{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REconocimiento facial utilizando el modelo Dlib a través\n",
    "# de la libreria face_recognition \n",
    "# Dliib utiliztiene dos modos de operación utilizando una CNN o un HOG\n",
    "# (Histograma de Gradientes Orientados) La CNN se recomienda utilizar cuando \n",
    "# Se ha instalado Dlib habilitando el uso de cuda este da mayor presición \n",
    "# EL HOG se recomienda cuando no se puede utilizar cuda \n",
    "import face_recognition\n",
    "# Imutils es una libreria sobre open CV que facilita el uso de herramientas \n",
    "# como el rescalamiento, la rotación o la translación de las imágenes\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos la lista de rostros con su etiqueta que ya ha sido pasada por un \n",
    "# pre procesamiento en dlib el cual nos da un vector de 128 elementos que \n",
    "# son una representación numerica de la cara detectada\n",
    "data = pickle.loads(open(\"./encoded_faces.pickle\", \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrimos el archivo de video a evaluar, en este caso uno ya grabado \n",
    "# que es clip que contien partes de alguna peliculas de HP \n",
    "stream = cv2.VideoCapture(\"./examples/example_video_02.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteramos por cada uno de los frames del video de entrada\n",
    "\n",
    "(frameExists, frame) = stream.read()\n",
    "# Creamos un writter el cual nos permitirá giuardar el nuevo video con las \n",
    "# caras detectas en disco\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "writer = cv2.VideoWriter(\"./results/test-small-02.mp4\", \n",
    "                    fourcc, 24, (frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "while frameExists:\n",
    "    # Open CV por defecto nos regresa la imagen en BGR en lugar de RGB \n",
    "    # Dlib funciona con las imagenes en formato RGB es por esto que tenemos\n",
    "    # que hacer un cambio en formato de color, estge se realiza con ayuda de \n",
    "    # el mismo Open CV\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    # Le damos un nuevo Ancho al fram de 750 px para unificar el tamaño de los  \n",
    "    # frames y de esta forma tener un tiempo de ejecución estandar con \n",
    "    # cualquier video que le pasemos \n",
    "    rgb = imutils.resize(rgb, width=750)\n",
    "    # Sacamos un ratio de transformación para despues poder encuadrar\n",
    "    # correctamente la cara en el video de salida\n",
    "    r = frame.shape[1] / float(rgb.shape[1])\n",
    "\n",
    "    # Detección de caras, con este método de face_recognition pasamos\n",
    "    # la imagen por la red neuronal para poder detectar los recuadros\n",
    "    # que encuadren cada cara, este método regresa una lista de puntos \n",
    "    # (arriba, derecha, abajo, izquierda)\n",
    "    boxes = face_recognition.face_locations(rgb, model=\"hog\")\n",
    "    # Sacamos para cada cara detectada la serie principal de puntos, ojos,\n",
    "    # nariz, boca, barbilla\n",
    "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "    names = []\n",
    "\n",
    "    # Para cada cara ya parametrizada detectada en el frame\n",
    "    for encoding in encodings:\n",
    "        # Buscamos cuales son las caras de entrenamiento con la menor\n",
    "        # distancia para esto usamos np.linalg.norm y buscamos el menor\n",
    "        # Este paso puede ser substituido por otra red neuronal, sin embargo,\n",
    "        # tenemos que considerar la velocidad de esta comparación contra la de\n",
    "        # la predicción de una red neuronal y evaluar la precisión \n",
    "        # para así poder determinar qué método cojnviene utilizar si se \n",
    "        # desea realizar analisis real-time de video.\n",
    "        # El último parámetro que utilizamnos es la tolerancia que damos a \n",
    "        # la similitud de los rostros\n",
    "        matches = face_recognition.compare_faces(data[\"encodings\"], \n",
    "                                                 encoding,0.555)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # Buscamos si hubo algún match en los rostros, de ser así\n",
    "        # buscamos el nombre con el que más coincidencias haya tenido\n",
    "        if True in matches:\n",
    "            # Hacemos una lista de todos los indices que fueron un match\n",
    "            matchedIdxs = [i for (i, b) in enumerate(matches) if b]\n",
    "            counts = {}\n",
    "\n",
    "            # Hacemos un conteo de cuales fueron las caras que hicieron match \n",
    "            for i in matchedIdxs:\n",
    "                name = data[\"names\"][i]\n",
    "                counts[name] = counts.get(name, 0) + 1\n",
    "\n",
    "            # Buscamos la cara con mayor numero de repeticiones\n",
    "            name = max(counts, key=counts.get)\n",
    "\n",
    "        # Agregamos el nombre a la lista de nombres en caso de no haber match \n",
    "        # se ingresara Unknown\n",
    "        names.append(name)\n",
    "\n",
    "    # por cada rostro reconocido en el frame creamos un recuadro en la \n",
    "    # posición de la cara y lo pintamos de verde si hubo match, de rojo \n",
    "    # si no hubo\n",
    "    for ((top, right, bottom, left), name) in zip(boxes, names):\n",
    "        # Hay que recordar que las coordenadas obtenidas son a partir de\n",
    "        # una imagen escalad por lo que tenemos que rescalar las posiciones que\n",
    "        # se obtuvieron con ayuda del ratio que sacamos con anterioridad\n",
    "        top = int(top * r)\n",
    "        right = int(right * r)\n",
    "        bottom = int(bottom * r)\n",
    "        left = int(left * r)\n",
    "        if name == 'Unknown':\n",
    "            colour=(0,255,0)\n",
    "        else:\n",
    "            colour = (255,0,0)\n",
    "\n",
    "        # Con ayuda de opencv pintamos el rectángulo sobre la cara \n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), \n",
    "                      colour, 2)\n",
    "        y = top - 15 if top - 15 > 15 else top + 15\n",
    "        # y agreamos el nombere sobre el recuadro\n",
    "        cv2.putText(frame, name, (left, y), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.75, colour, 2)\n",
    "        \n",
    "        # Escribimos nuestro nuevo cuadro a nuestro video de salida\n",
    "        writer.write(frame)\n",
    "\n",
    "    # Mosrtamos el nuevo cuadro en Tiempo real\n",
    "    cv2.imshow(\"Harry Potter\", frame)\n",
    "    # Leemos el siguiente frame\n",
    "    (frameExists, frame) = stream.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cerramos el stream\n",
    "stream.release()\n",
    "# Liberamos el Writer\n",
    "writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
